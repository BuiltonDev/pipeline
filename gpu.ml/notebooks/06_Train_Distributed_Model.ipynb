{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Model on Distributed Cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Cluster Spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "cluster = tf.train.ClusterSpec({\"local\": [\"localhost:2222\", \"localhost:2223\"]})"
    "cluster = tf.train.ClusterSpec(\n",
    "    {\"worker\": [\"localhost:2222\",\"localhost:2223\"]}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
>>>>>>> fluxcapacitor/master
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
<<<<<<< HEAD
    "## Start Server \"Task 0\" (localhost:2222)"
=======
    "## Start Worker 0 (localhost:2222)"
>>>>>>> fluxcapacitor/master
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "server0 = tf.train.Server(cluster, job_name=\"local\", task_index=0)\n",
    "\n",
    "print(server0)"
=======
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tensorflow.python.training.server_lib.Server object at 0x7f81786c1978>\n"
     ]
    }
   ],
   "source": [
    "worker0 = tf.train.Server(cluster, \n",
    "                          job_name=\"worker\",\n",
    "                          task_index=0,\n",
    "                          start=True)\n",
    "\n",
    "print(worker0)"
>>>>>>> fluxcapacitor/master
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
<<<<<<< HEAD
    "## Start Server \"Task 1\" (localhost:2223)"
=======
    "## Start Worker 1\" (localhost:2223)"
>>>>>>> fluxcapacitor/master
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "server1 = tf.train.Server(cluster, job_name=\"local\", task_index=1)\n",
    "\n",
    "print(server1)"
=======
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tensorflow.python.training.server_lib.Server object at 0x7f817861e828>\n"
     ]
    }
   ],
   "source": [
    "worker1 = tf.train.Server(cluster, \n",
    "                          job_name=\"worker\",\n",
    "                          task_index=1,\n",
    "                          start=True)\n",
    "\n",
    "print(worker1)"
>>>>>>> fluxcapacitor/master
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
<<<<<<< HEAD
    "## Define a Computationally-intensive TensorFlow Graph"
=======
    "## Define Computationally-Intensive Graph\n",
    "Note that we're not assigning devices.  TensorFlow will automatically select GPU if available."
>>>>>>> fluxcapacitor/master
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
   "metadata": {},
=======
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
>>>>>>> fluxcapacitor/master
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "n = 2\n",
    "c1 = tf.Variable([])\n",
    "c2 = tf.Variable([])\n",
    "\n",
    "def matpow(M, n):\n",
    "    if n < 1: \n",
    "        return M\n",
    "    else:\n",
<<<<<<< HEAD
    "        return tf.matmul(M, matpow(M, n-1))"
=======
    "        return tf.matmul(M, matpow(M, n-1))\n",
    "\n",
    "A = tf.random_normal(shape=[10000, 10000])\n",
    "c1 = matpow(A,n)\n",
    "\n",
    "B = tf.random_normal(shape=[10000, 10000])\n",
    "c2 = matpow(B,n)\n",
    "\n",
    "sum = c1 + c2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create `tf.train.MonitoredTrainingSession`\n",
    "There are may `tf.train.Hook` implementations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  1016.33886719   5086.08496094 -21478.5        ..., -23559.35742188\n",
      "   -8796.45507812   2257.31713867]\n",
      " [ 22592.65625      7863.86621094  -4279.58886719 ..., -18607.12109375\n",
      "      92.41992188  21984.7421875 ]\n",
      " [ -8022.40380859 -16408.69726562 -18995.96484375 ...,  -6476.82861328\n",
      "   -3648.82128906 -24430.84375   ]\n",
      " ..., \n",
      " [  8047.33935547 -28624.1875      -6854.82128906 ..., -32593.359375\n",
      "   29987.5546875    9121.9296875 ]\n",
      " [ -9352.12109375  31952.13085938  15410.90820312 ...,  -3708.57177734\n",
      "   37230.53515625  -2356.59399414]\n",
      " [   842.046875     6426.86816406    931.88232422 ..., -14624.67578125\n",
      "   -1867.80810547  -3675.32055664]]\n",
      "Execution time: 0:00:03.744440\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import datetime\n",
    "\n",
    "with tf.train.MonitoredTrainingSession(worker0.target,\n",
    "                                       is_chief=True) as sess:\n",
    "    start_time = datetime.datetime.now()\n",
    "    print(sess.run(sum))\n",
    "    print(\"Execution time: \" \n",
    "          + str(datetime.datetime.now() - start_time))"
>>>>>>> fluxcapacitor/master
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
<<<<<<< HEAD
    "## Assign Devices Manually "
=======
    "## Execute Graph on Manually-Assigned Devices "
>>>>>>> fluxcapacitor/master
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All CPU Devices\n",
    "Note the execution time."
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "with tf.device(\"/job:local/task:0/cpu:0\"):\n",
    "    A = tf.random_normal(shape=[10000, 10000])\n",
    "    c1 = matpow(A,n)\n",
    "\n",
    "with tf.device(\"/job:local/task:1/cpu:0\"):\n",
    "    B = tf.random_normal(shape=[10000, 10000])\n",
    "    c2 = matpow(B,n)\n",
    "\n",
    "with tf.Session(\"grpc://127.0.0.1:2222\") as sess:\n",
    "    sum = c1 + c2\n",
=======
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  -509.796875     1314.65673828  23200.33984375 ...,  -3905.23828125\n",
      "    7695.48291016   -202.14257812]\n",
      " [ -4774.43359375  -2562.40136719  11767.11523438 ...,   8130.13916016\n",
      "   16203.84277344  18745.92578125]\n",
      " [ -1529.10449219  -3331.62255859  -4387.42773438 ...,  -5168.890625\n",
      "    5861.85888672 -16078.02050781]\n",
      " ..., \n",
      " [-29718.00976562 -20533.46875      9069.92089844 ..., -18745.94335938\n",
      "  -12319.10351562   7450.47265625]\n",
      " [-13714.77832031  -4216.63867188  14876.51660156 ...,  17193.30859375\n",
      "    7786.05810547   9686.54980469]\n",
      " [ 13452.03320312   1807.39306641 -20156.81445312 ...,  28342.42382812\n",
      "   19215.2734375    7902.58642578]]\n",
      "Execution time: 0:00:30.404982\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "n = 2\n",
    "c1 = tf.Variable([])\n",
    "c2 = tf.Variable([])\n",
    "\n",
    "def matpow(M, n):\n",
    "    if n < 1: \n",
    "        return M\n",
    "    else:\n",
    "        return tf.matmul(M, matpow(M, n-1))\n",
    "\n",
    "with tf.device(\"/job:worker/task:0/cpu:0\"):\n",
    "    A = tf.random_normal(shape=[10000, 10000])\n",
    "    c1 = matpow(A,n)\n",
    "\n",
    "with tf.device(\"/job:worker/task:1/cpu:0\"):\n",
    "    B = tf.random_normal(shape=[10000, 10000])\n",
    "    c2 = matpow(B,n)\n",
    "\n",
    "sum = c1 + c2\n",
    "\n",
    "import tensorflow as tf\n",
    "import datetime\n",
    "\n",
    "with tf.train.MonitoredTrainingSession(worker0.target,\n",
    "                                       is_chief=True) as sess:\n",
>>>>>>> fluxcapacitor/master
    "    start_time = datetime.datetime.now()\n",
    "    print(sess.run(sum))\n",
    "    print(\"Execution time: \" \n",
    "          + str(datetime.datetime.now() - start_time))\n",
    "          "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CPU and GPU\n",
<<<<<<< HEAD
    "Note the execution time."
=======
    "Note the reduced execution time from the all-CPU execution."
>>>>>>> fluxcapacitor/master
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device(\"/job:local/task:0/gpu:0\"):\n",
    "    A = tf.random_normal(shape=[10000, 10000])\n",
    "    c1 = matpow(A,n)\n",
    "\n",
    "with tf.device(\"/job:local/task:1/cpu:0\"):\n",
    "    B = tf.random_normal(shape=[10000, 10000])\n",
    "    c2 = matpow(B,n)\n",
    "\n",
    "with tf.Session(\"grpc://127.0.0.1:2222\") as sess:\n",
    "    sum = c1 + c2\n",
    "    start_time = datetime.datetime.now()\n",
    "    print(sess.run(sum))\n",
    "    print(\"Execution time: \" \n",
    "          + str(datetime.datetime.now() - start_time))"
=======
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  1294.29589844 -11670.43945312  -2398.37841797 ...,  25865.5390625\n",
      "   -5128.17919922 -15327.59472656]\n",
      " [  1014.58007812 -12306.48925781  -7836.98291016 ...,   -387.49804688\n",
      "    5531.7578125   -1679.28503418]\n",
      " [-11163.03222656 -19190.5703125   -5518.64355469 ..., -11151.46679688\n",
      "   -9940.95214844 -13142.30175781]\n",
      " ..., \n",
      " [ 13368.81054688  11029.58300781  -8992.62890625 ...,   5036.75244141\n",
      "   -8550.47460938     28.94140625]\n",
      " [   985.68408203  12802.31933594 -11027.72851562 ...,  10220.23242188\n",
      "   19238.91015625  16036.50683594]\n",
      " [-18154.91796875 -12422.08300781  -5359.39648438 ..., -21455.4609375\n",
      "  -14445.66015625 -26871.25      ]]\n",
      "Execution time: 0:00:17.447517\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "n = 2\n",
    "c1 = tf.Variable([])\n",
    "c2 = tf.Variable([])\n",
    "\n",
    "def matpow(M, n):\n",
    "    if n < 1: \n",
    "        return M\n",
    "    else:\n",
    "        return tf.matmul(M, matpow(M, n-1))\n",
    "\n",
    "with tf.device(\"/job:worker/task:0/gpu:0\"):\n",
    "    A = tf.random_normal(shape=[10000, 10000])\n",
    "    c1 = matpow(A,n)\n",
    "\n",
    "with tf.device(\"/job:worker/task:1/cpu:0\"):\n",
    "    B = tf.random_normal(shape=[10000, 10000])\n",
    "    c2 = matpow(B,n)\n",
    "\n",
    "sum = c1 + c2\n",
    "\n",
    "import tensorflow as tf\n",
    "import datetime\n",
    "\n",
    "with tf.train.MonitoredTrainingSession(worker0.target,\n",
    "                                       is_chief=True) as sess:\n",
    "    start_time = datetime.datetime.now()\n",
    "    print(sess.run(sum))\n",
    "    print(\"Execution time: \" \n",
    "          + str(datetime.datetime.now() - start_time))\n",
    "          "
>>>>>>> fluxcapacitor/master
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All GPU Devices\n",
<<<<<<< HEAD
    "Note the execution time."
=======
    "Note the execution time is slower than when we didn't specify devices.  Why is that?"
>>>>>>> fluxcapacitor/master
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device(\"/job:local/task:0/gpu:0\"):\n",
    "    A = tf.random_normal(shape=[10000, 10000])\n",
    "    c1 = matpow(A,n)\n",
    "\n",
    "with tf.device(\"/job:local/task:1/gpu:0\"):\n",
    "    B = tf.random_normal(shape=[10000, 10000])\n",
    "    c2 = matpow(B,n)\n",
    "\n",
    "with tf.Session(\"grpc://127.0.0.1:2222\") as sess:\n",
    "    sum = c1 + c2\n",
    "    start_time = datetime.datetime.now()\n",
    "    print(sess.run(sum))\n",
    "    print(\"Execution time: \" \n",
    "          + str(datetime.datetime.now() - start_time))"
=======
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  1602.25048828  -3084.27905273  10950.75585938 ...,   2505.19482422\n",
      "   -5372.36816406  -5412.41259766]\n",
      " [ 17306.75390625  14299.77539062  -6978.29052734 ...,   4840.109375\n",
      "   -7943.2578125    6473.67773438]\n",
      " [ 21306.8515625  -21384.18359375 -19334.47265625 ...,   2961.40869141\n",
      "   -6882.56689453   2505.97949219]\n",
      " ..., \n",
      " [-11346.84960938  -3797.17773438 -17888.81640625 ...,   1532.88037109\n",
      "   -4650.39355469  10317.73730469]\n",
      " [ -1885.30297852    487.67919922 -36493.9453125  ...,    751.8651123\n",
      "  -12599.59570312  -8101.55029297]\n",
      " [-35922.453125    13188.16113281  -5478.03710938 ...,    338.32543945\n",
      "    8220.47460938   -179.34619141]]\n",
      "Execution time: 0:00:06.655171\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "n = 2\n",
    "c1 = tf.Variable([])\n",
    "c2 = tf.Variable([])\n",
    "\n",
    "def matpow(M, n):\n",
    "    if n < 1: \n",
    "        return M\n",
    "    else:\n",
    "        return tf.matmul(M, matpow(M, n-1))\n",
    "\n",
    "with tf.device(\"/job:worker/task:0/gpu:0\"):\n",
    "    A = tf.random_normal(shape=[10000, 10000])\n",
    "    c1 = matpow(A,n)\n",
    "\n",
    "with tf.device(\"/job:worker/task:1/gpu:0\"):\n",
    "    B = tf.random_normal(shape=[10000, 10000])\n",
    "    c2 = matpow(B,n)\n",
    "\n",
    "sum = c1 + c2\n",
    "\n",
    "import tensorflow as tf\n",
    "import datetime\n",
    "\n",
    "with tf.train.MonitoredTrainingSession(worker0.target,\n",
    "                                       is_chief=True) as sess:\n",
    "    start_time = datetime.datetime.now()\n",
    "    print(sess.run(sum))\n",
    "    print(\"Execution time: \" \n",
    "          + str(datetime.datetime.now() - start_time))\n",
    "          "
>>>>>>> fluxcapacitor/master
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
<<<<<<< HEAD
    "### Auto-assign Device by TensorFlow (Round-Robin by Default)\n",
    "Note the execution time."
=======
    "## Execute Graph with Auto-Assigned Devices \n",
    "`tf.train.replica_device_setter()` uses round-robin by default. Note the execution time."
>>>>>>> fluxcapacitor/master
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let TensorFlow decide the device placement\n",
    "with tf.device(tf.train.replica_device_setter(worker_device=\"/job:worker/task:0\",\n",
    "                                              cluster=cluster)):\n",
    "    A = tf.random_normal(shape=[10000, 10000])\n",
    "    c1 = matpow(A,n)\n",
    "\n",
    "with tf.device(tf.train.replica_device_setter(worker_device=\"/job:worker/task:1\",\n",
    "                                              cluster=cluster)):\n",
    "    B = tf.random_normal(shape=[10000, 10000])\n",
    "    c2 = matpow(B,n)\n",
    "\n",
    "with tf.Session(\"grpc://127.0.0.1:2222\") as sess:\n",
    "    sum = c1 + c2\n",
    "    start_time = datetime.datetime.now()\n",
    "    print(sess.run(sum))\n",
    "    print(\"Multi node computation time: \" \n",
    "          + str(datetime.datetime.now() - start_time))"
=======
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-33297.84375    -20306.92773438 -27761.7890625  ..., -42657.953125\n",
      "    8224.44726562   5156.65625   ]\n",
      " [    75.38378906   3666.71875     -1740.1105957  ...,  -8287.85546875\n",
      "   -6599.88183594  -1797.16503906]\n",
      " [-22654.90429688 -27462.53125    -15845.95214844 ...,   3172.30493164\n",
      "  -25671.390625     5785.87597656]\n",
      " ..., \n",
      " [-11659.15820312 -12027.22265625 -15839.97851562 ...,   5913.44677734\n",
      "   -1020.65478516   8333.6796875 ]\n",
      " [  -987.72363281  -4550.59375    -19268.74414062 ...,  14845.99609375\n",
      "   10885.14453125 -20765.82421875]\n",
      " [  -144.18981934 -30101.40429688  14654.04296875 ...,   6185.74023438\n",
      "   -2888.77050781   4643.55126953]]\n",
      "Execution time: 0:00:03.805252\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "n = 2\n",
    "c1 = tf.Variable([])\n",
    "c2 = tf.Variable([])\n",
    "\n",
    "def matpow(M, n):\n",
    "    if n < 1: \n",
    "        return M\n",
    "    else:\n",
    "        return tf.matmul(M, matpow(M, n-1))\n",
    "\n",
    "with tf.device(tf.train.replica_device_setter(worker_device=\"/job:worker/task:0\",\n",
    "                                              cluster=cluster)):   \n",
    "    A = tf.random_normal(shape=[10000, 10000])\n",
    "    c1 = matpow(A,n)\n",
    "\n",
    "with tf.device(tf.train.replica_device_setter(worker_device=\"/job:worker/task:1\",                           cluster=cluster)):    \n",
    "    B = tf.random_normal(shape=[10000, 10000])\n",
    "    c2 = matpow(B,n)\n",
    "\n",
    "sum = c1 + c2\n",
    "\n",
    "import tensorflow as tf\n",
    "import datetime\n",
    "\n",
    "with tf.train.MonitoredTrainingSession(worker0.target,\n",
    "                                       is_chief=True) as sess:\n",
    "    start_time = datetime.datetime.now()\n",
    "    print(sess.run(sum))\n",
    "    print(\"Execution time: \" \n",
    "          + str(datetime.datetime.now() - start_time))\n",
    "          "
>>>>>>> fluxcapacitor/master
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
<<<<<<< HEAD
=======
  "anaconda-cloud": {},
>>>>>>> fluxcapacitor/master
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
