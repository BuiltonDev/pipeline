{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Model with CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.python.client import timeline\n",
    "import pylab\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "tf.logging.set_verbosity(tf.logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_samples = 100000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1494219833\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime \n",
    "\n",
    "version = int(datetime.now().strftime(\"%s\"))\n",
    "print(version)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_device_placement: true\n",
      "\n",
      "<tensorflow.python.client.session.Session object at 0x7f65d409ba58>\n"
     ]
    }
   ],
   "source": [
    "config = tf.ConfigProto(\n",
    "  log_device_placement=True,\n",
    ")\n",
    "print(config)\n",
    "\n",
    "sess = tf.Session(config=config)\n",
    "print(sess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and Shuffle Training Data \n",
    "`tf.train.shuffle_batch` uses `tf.RandomShuffleQueue` internally.\n",
    "\n",
    "`min_after_dequeue` defines the buffer size when randomly sampling.  Larger buffers require more RAM, but provide better shuffling characteristics.\n",
    "\n",
    "`capacity` must be larger than `min_after_dequeue`.  The difference in size becomes the prefetch maximum.\n",
    "\n",
    "pylab.plot(x_test, y_test, '.')"
    "`capacity` = `batch_size` * (`num_threads` + `some_safety_margin`) + `min_after_dequeue`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Enqueue Thread Pool Size: 27\n"
     ]
    }
   ],
   "source": [
    "training_queue = tf.train.string_input_producer([\n",
    "  \"hdfs://127.0.0.1:39000/linear/training.csv\",\n",
    "])\n",
    "\n",
    "training_reader = tf.TextLineReader()\n",
    "_, training_value = training_reader.read(training_queue)\n",
    "\n",
    "x_training, y_training = tf.decode_csv(training_value, [[0.0],[0.0]])\n",
    "\n",
    "x_training_batch, y_training_batch = \\\n",
    "    tf.train.shuffle_batch([x_training, y_training], \n",
    "                           batch_size=1000,\n",
    "                           capacity=25000,\n",
    "                           num_threads=24,\n",
    "                           min_after_dequeue=10000)\n",
    "\n",
    "#with tf.Session() as sess:\n",
    "training_coord = tf.train.Coordinator()\n",
    "\n",
    "training_enqueue_threads = tf.train.start_queue_runners(sess=sess, \n",
    "                                                        coord=training_coord)\n",
    "\n",
    "print(\"Training Enqueue Thread Pool Size: %d\" % len(training_enqueue_threads))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
<<<<<<< HEAD
    "with tf.device(\"/cpu:0\"):\n",
    "  y_observed = tf.placeholder(shape=[None], dtype=tf.float32, name='y_observed')\n",
    "  print(y_observed)\n",
    "\n",
    "  loss_op = tf.reduce_mean(tf.square(y_pred - y_observed))\n",
    "\n",
    "  optimizer_op = tf.train.GradientDescentOptimizer(0.025)  \n",
    "  train_op = optimizer_op.minimize(loss_op)  \n",
    "\n",
    "  print(\"loss:\", loss_op)\n",
    "  print(\"optimizer:\", optimizer_op)\n",
    "  print(\"train:\", train_op)"
=======
    "# TODO:\n",
    "# pylab.plot(x_train, y_train, '.')"
>>>>>>> fluxcapacitor/master
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO:\n",
    "#pylab.plot(x_test, y_test, '.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'weights:0' shape=() dtype=float32_ref>\n",
      "<tf.Variable 'bias:0' shape=() dtype=float32_ref>\n",
      "Tensor(\"add:0\", shape=(1000,), dtype=float32, device=/device:GPU:0)\n",
      "Loss Scalar:  Tensor(\"Mean:0\", shape=(), dtype=float32, device=/device:GPU:0)\n",
      "Optimizer Op:  <tensorflow.python.training.gradient_descent.GradientDescentOptimizer object at 0x7f658c06c550>\n",
      "Training Op name: \"GradientDescent\"\n",
      "op: \"NoOp\"\n",
      "input: \"^GradientDescent/update_weights/ApplyGradientDescent\"\n",
      "input: \"^GradientDescent/update_bias/ApplyGradientDescent\"\n",
      "device: \"/device:GPU:0\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# TODO:\n",
    "\n",
    "with tf.device(\"/gpu:0\"):\n",
    "    W = tf.get_variable(shape=[], name='weights')\n",
    "    print(W)\n",
    "\n",
    "    b = tf.get_variable(shape=[], name='bias')\n",
    "    print(b)\n",
    "    \n",
    "\n",
    "with tf.device(\"/gpu:0\"):\n",
    "    y_pred_batch = W * x_training_batch + b\n",
    "    print(y_pred_batch)\n",
    "\n",
    "    \n",
    "with tf.device(\"/gpu:0\"):\n",
    "#    y_observed_batch = tf.placeholder(shape=[None], dtype=tf.float32, name='y_observed')\n",
    "#    print(y_observed_batch)\n",
    "    \n",
    "    loss_op = tf.reduce_mean(tf.square(y_pred_batch - y_training_batch))\n",
    "    optimizer_op = tf.train.GradientDescentOptimizer(0.025)\n",
    "    training_op = optimizer_op.minimize(loss_op)  \n",
    "\n",
    "    print(\"Loss Scalar: \", loss_op)\n",
    "    print(\"Optimizer Op: \", optimizer_op)\n",
    "    print(\"Training Op\", training_op)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## View Model Graph in Tensorboard\n",
    "\n",
    "Navigate to the Graph tab at this URL:\n",
    "\n",
    "http://[ip-address]:6006"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Randomly Initialize Variables (Weights and Bias)\n",
    "The goal is to learn more accurate Weights and Bias during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name: \"init\"\n",
      "op: \"NoOp\"\n",
      "input: \"^weights/Assign\"\n",
      "input: \"^bias/Assign\"\n",
      "device: \"/device:GPU:0\"\n",
      "\n",
      "W: 1.659906\n",
      "b: -0.596357\n"
     ]
    }
   ],
   "source": [
    "with tf.device(\"/gpu:0\"):\n",
    "    init_op = tf.global_variables_initializer()\n",
    "    print(init_op)\n",
    "\n",
    "sess.run(init_op)\n",
    "print(\"W: %f\" % sess.run(W))\n",
    "print(\"b: %f\" % sess.run(b))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## View Accuracy of Initial Random Variables (Pre-Training)\n",
    "This should be relatively low because we have not trained the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 21.479048\n",
      "CPU times: user 48 ms, sys: 20 ms, total: 68 ms\n",
      "Wall time: 23.9 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "loss = sess.run(loss_op)\n",
    "\n",
    "print(\"Accuracy: %f\" % (loss*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training_summary_writer = tf.summary.FileWriter('/root/tensorboard/linear/cpu/%s/training' % version, \n",
    "                                                 graph=tf.get_default_graph())\n",
    "\n",
    "#validation_summary_writer = tf.summary.FileWriter('root/tensorboard/linear/cpu/%s/validation' % version, \n",
    "#                                                 graph=tf.get_default_graph())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Loss Summary Operations for Tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loss_summary_scalar_op = tf.summary.scalar('loss', loss_op)\n",
    "loss_summary_merge_all_op = tf.summary.merge_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the Model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [0.5244115, 0.073068172]\n",
      "100 [0.40456215, 0.13596374]\n",
      "200 [0.31920508, 0.1822772]\n",
      "300 [0.25748399, 0.21509486]\n",
      "CPU times: user 2min 36s, sys: 1min 5s, total: 3min 42s\n",
      "Wall time: 1min 9s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "run_metadata = tf.RunMetadata()\n",
    "\n",
    "max_steps = 401\n",
    "for step in range(max_steps - 1):\n",
    "    if (step < max_steps):\n",
    "        training_summary_log, _ = sess.run([loss_summary_merge_all_op, training_op]) \n",
    "    else:  \n",
    "        training_summary_log, _ = sess.run([loss_summary_merge_all_op, training_op],\n",
    "                                            options=tf.RunOptions(trace_level=tf.RunOptions.FULL_TRACE), \n",
    "                                            run_metadata=run_metadata)\n",
    "    \n",
    "    trace = timeline.Timeline(step_stats=run_metadata.step_stats)    \n",
    "    with open('cpu-timeline.json', 'w') as trace_file:\n",
    "        trace_file.write(trace.generate_chrome_trace_format(show_memory=True))\n",
    "\n",
    "    if step % 10 == 0:\n",
    "        training_summary_writer.add_summary(training_summary_log, step)\n",
    "        training_summary_writer.flush()\n",
    "        if step % 100 == 0:\n",
    "            print(step, sess.run([W, b]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#pylab.plot(x_train, y_train, '.', label=\"target\")\n",
    "#pylab.plot(x_train, sess.run(y_pred, feed_dict={x_observed: x_train, y_observed: y_train}), \".\", label=\"predicted\")\n",
    "#pylab.legend()\n",
    "#pylab.ylim(0, 1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## View Loss Scalar Summary in Tensorboard\n",
    "\n",
    "Navigate to the Scalars tab at this URL:\n",
    "\n",
    "http://[ip-address]:6006"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Model Graph and Variables for Deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name: \"shuffle_batch:0\"\n",
      "dtype: DT_FLOAT\n",
      "tensor_shape {\n",
      "  dim {\n",
      "    size: 1000\n",
      "  }\n",
      "}\n",
      "\n",
      "name: \"add:0\"\n",
      "dtype: DT_FLOAT\n",
      "tensor_shape {\n",
      "  dim {\n",
      "    size: 1000\n",
      "  }\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.saved_model import utils\n",
    "\n",
    "tensor_info_x_observed = utils.build_tensor_info(x_training_batch)\n",
    "print(tensor_info_x_observed)\n",
    "\n",
    "tensor_info_y_pred = utils.build_tensor_info(y_pred_batch)\n",
    "print(tensor_info_y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/root/models/linear/cpu/1494219833\n"
     ]
    }
   ],
   "source": [
    "export_path = \"/root/models/linear/cpu/%s\" % version\n",
    "\n",
    "print(export_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:No assets to save.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:Error reported to Coordinator: <class 'tensorflow.python.framework.errors_impl.InvalidArgumentError'>, Cannot assign a device to node 'save/ShardedFilename': Could not satisfy explicit device specification '/device:GPU:0' because no supported kernel for GPU devices is available.\n",
      "\t [[Node: save/ShardedFilename = ShardedFilename[_device=\"/device:GPU:0\"](save/StringJoin, save/ShardedFilename/shard, save/num_shards)]]\n",
      "\n",
      "Caused by op 'save/ShardedFilename', defined at:\n",
      "  File \"/opt/conda/lib/python3.5/runpy.py\", line 193, in _run_module_as_main\n",
      "    \"__main__\", mod_spec)\n",
      "  File \"/opt/conda/lib/python3.5/runpy.py\", line 85, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/conda/lib/python3.5/site-packages/ipykernel/__main__.py\", line 3, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/opt/conda/lib/python3.5/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n",
      "    app.start()\n",
      "  File \"/opt/conda/lib/python3.5/site-packages/ipykernel/kernelapp.py\", line 477, in start\n",
      "    ioloop.IOLoop.instance().start()\n",
      "  File \"/opt/conda/lib/python3.5/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n",
      "    super(ZMQIOLoop, self).start()\n",
      "  File \"/opt/conda/lib/python3.5/site-packages/tornado/ioloop.py\", line 887, in start\n",
      "    handler_func(fd_obj, events)\n",
      "  File \"/opt/conda/lib/python3.5/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n",
      "    self._handle_recv()\n",
      "  File \"/opt/conda/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n",
      "    self._run_callback(callback, msg)\n",
      "  File \"/opt/conda/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n",
      "    callback(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.5/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 276, in dispatcher\n",
      "    return self.dispatch_shell(stream, msg)\n",
      "  File \"/opt/conda/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 228, in dispatch_shell\n",
      "    handler(stream, idents, msg)\n",
      "  File \"/opt/conda/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 390, in execute_request\n",
      "    user_expressions, allow_stdin)\n",
      "  File \"/opt/conda/lib/python3.5/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n",
      "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
      "  File \"/opt/conda/lib/python3.5/site-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n",
      "    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2717, in run_cell\n",
      "    interactivity=interactivity, compiler=compiler, result=result)\n",
      "  File \"/opt/conda/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2821, in run_ast_nodes\n",
      "    if self.run_code(code, result):\n",
      "  File \"/opt/conda/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2881, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-62-9c1241195f92>\", line 20, in <module>\n",
      "    legacy_init_op=legacy_init_op)\n",
      "  File \"/opt/conda/lib/python3.5/site-packages/tensorflow/python/saved_model/builder_impl.py\", line 432, in add_meta_graph_and_variables\n",
      "    allow_empty=True)\n",
      "  File \"/opt/conda/lib/python3.5/site-packages/tensorflow/python/training/saver.py\", line 1056, in __init__\n",
      "    self.build()\n",
      "  File \"/opt/conda/lib/python3.5/site-packages/tensorflow/python/training/saver.py\", line 1086, in build\n",
      "    restore_sequentially=self._restore_sequentially)\n",
      "  File \"/opt/conda/lib/python3.5/site-packages/tensorflow/python/training/saver.py\", line 685, in build\n",
      "    save_tensor = self._AddShardedSaveOps(filename_tensor, per_device)\n",
      "  File \"/opt/conda/lib/python3.5/site-packages/tensorflow/python/training/saver.py\", line 361, in _AddShardedSaveOps\n",
      "    return self._AddShardedSaveOpsForV2(filename_tensor, per_device)\n",
      "  File \"/opt/conda/lib/python3.5/site-packages/tensorflow/python/training/saver.py\", line 333, in _AddShardedSaveOpsForV2\n",
      "    num_shards_tensor)\n",
      "  File \"/opt/conda/lib/python3.5/site-packages/tensorflow/python/training/saver.py\", line 264, in sharded_filename\n",
      "    return gen_io_ops._sharded_filename(filename_tensor, shard, num_shards)\n",
      "  File \"/opt/conda/lib/python3.5/site-packages/tensorflow/python/ops/gen_io_ops.py\", line 802, in _sharded_filename\n",
      "    shard=shard, num_shards=num_shards, name=name)\n",
      "  File \"/opt/conda/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py\", line 768, in apply_op\n",
      "    op_def=op_def)\n",
      "  File \"/opt/conda/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 2336, in create_op\n",
      "    original_op=self._default_original_op, op_def=op_def)\n",
      "  File \"/opt/conda/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 1228, in __init__\n",
      "    self._traceback = _extract_stack()\n",
      "\n",
      "InvalidArgumentError (see above for traceback): Cannot assign a device to node 'save/ShardedFilename': Could not satisfy explicit device specification '/device:GPU:0' because no supported kernel for GPU devices is available.\n",
      "\t [[Node: save/ShardedFilename = ShardedFilename[_device=\"/device:GPU:0\"](save/StringJoin, save/ShardedFilename/shard, save/num_shards)]]\n",
      "\n"
     ]
    },
    {
     "ename": "NotFoundError",
     "evalue": "FeedInputs: unable to find feed output save/Const:0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m/opt/conda/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1050\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1051\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1032\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1033\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1034\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.5/contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type, value, traceback)\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m                 \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.5/site-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36mraise_exception_on_not_ok_status\u001b[0;34m()\u001b[0m\n\u001b[1;32m    465\u001b[0m           \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpywrap_tensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 466\u001b[0;31m           pywrap_tensorflow.TF_GetCode(status))\n\u001b[0m\u001b[1;32m    467\u001b[0m   \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotFoundError\u001b[0m: FeedInputs: unable to find feed output save/Const:0",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-62-9c1241195f92>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m   signature_def_map={\"predict_linear\":prediction_signature,\n\u001b[1;32m     19\u001b[0m                       signature_constants.DEFAULT_SERVING_SIGNATURE_DEF_KEY:prediction_signature}, \n\u001b[0;32m---> 20\u001b[0;31m                       legacy_init_op=legacy_init_op)\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.5/site-packages/tensorflow/python/saved_model/builder_impl.py\u001b[0m in \u001b[0;36madd_meta_graph_and_variables\u001b[0;34m(self, sess, tags, signature_def_map, assets_collection, legacy_init_op, clear_devices, main_op)\u001b[0m\n\u001b[1;32m    436\u001b[0m     \u001b[0;31m# SavedModel can be copied or moved, this avoids the checkpoint state to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m     \u001b[0;31m# become outdated.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 438\u001b[0;31m     \u001b[0msaver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvariables_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrite_meta_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrite_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    439\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m     \u001b[0;31m# Export the meta graph def.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.5/site-packages/tensorflow/python/training/saver.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, sess, save_path, global_step, latest_filename, meta_graph_suffix, write_meta_graph, write_state)\u001b[0m\n\u001b[1;32m   1389\u001b[0m       model_checkpoint_path = sess.run(\n\u001b[1;32m   1390\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msaver_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_tensor_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1391\u001b[0;31m           {self.saver_def.filename_tensor_name: checkpoint_file})\n\u001b[0m\u001b[1;32m   1392\u001b[0m       \u001b[0mmodel_checkpoint_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_checkpoint_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1393\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mwrite_state\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    784\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    785\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 786\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    787\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    992\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    993\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 994\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    995\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    996\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1042\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1043\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1044\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1045\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1046\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/opt/conda/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1062\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1063\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1064\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1065\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1066\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotFoundError\u001b[0m: FeedInputs: unable to find feed output save/Const:0"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.saved_model import builder as saved_model_builder\n",
    "from tensorflow.python.saved_model import signature_constants\n",
    "from tensorflow.python.saved_model import signature_def_utils\n",
    "from tensorflow.python.saved_model import tag_constants\n",
    "\n",
    "with tf.device(\"/cpu:0\"):\n",
    "  builder = saved_model_builder.SavedModelBuilder(export_path)\n",
    "\n",
    "prediction_signature =  signature_def_utils.build_signature_def(\n",
    "    inputs = {'inputs': tensor_info_x_observed}, \n",
    "    outputs = {'outputs': tensor_info_y_pred}, \n",
    "    method_name = signature_constants.PREDICT_METHOD_NAME)            \n",
    "\n",
    "legacy_init_op = tf.group(tf.tables_initializer(), name='legacy_init_op')\n",
    "\n",
    "builder.add_meta_graph_and_variables(sess, \n",
    "  [tag_constants.SERVING],\n",
    "  signature_def_map={\"predict_linear\":prediction_signature,\n",
    "                      signature_constants.DEFAULT_SERVING_SIGNATURE_DEF_KEY:prediction_signature}, \n",
    "                      legacy_init_op=legacy_init_op)\n",
    "\n",
    "builder.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
<<<<<<< HEAD
    "### Look at the Model On Disk\n",
    "\n",
    "You must replace `[version]` with the version number from above ^^"
=======
    "## Save Graph for Optimization and Transformation\n",
    "We will use this later."
>>>>>>> fluxcapacitor/master
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.framework import graph_io\n",
    "\n",
    "graph_io.write_graph(sess.graph, \n",
    "                     \"/root/models/optimize_me/\", \n",
    "                     \"unoptimized_cpu.pb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## View Saved Model on Disk\n",
    "\n",
    "You must replace `[version]` with the version number from above ^^"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "ls -l /root/models/linear/cpu/[version]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validate Model\n",
    "This should be relatively high after training the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "validation_queue = tf.train.string_input_producer([\n",
    "  \"hdfs://127.0.0.1:39000/linear/validation.csv\",\n",
    "])\n",
    "\n",
    "validation_reader = tf.TextLineReader()\n",
    "_, validation_value = validation_reader.read(validation_queue)\n",
    "\n",
    "x_validation, y_validation = tf.decode_csv(validation_value, [[0.0],[0.0]])\n",
    "\n",
    "x_validation_batch, y_validation_batch = \\\n",
    "    tf.train.batch([x_validation, y_validation], \n",
    "                    batch_size=100,\n",
    "                    capacity=2000)\n",
    "\n",
    "validation_coord = tf.train.Coordinator()\n",
    "\n",
    "validation_enqueue_threads = tf.train.start_queue_runners(sess=sess,\n",
    "                                                          coord=validation_coord)\n",
    "print(\"Validation Enqueue Thread Pool Size: %d\" % len(validation_enqueue_threads))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training_coord.request_stop()\n",
    "training_coord.join(training_enqueue_threads)\n",
    "\n",
    "validation_coord.request_stop()\n",
    "validation_coord.join(validation_enqueue_threads)\n",
    "\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
