{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimize Trained CPU Model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Types of Optimizations Applied for Inference\n",
    "* Remove training-only operations (checkpoint saving, drop out)\n",
    "* Strip out unused nodes\n",
    "* Remove debug operations\n",
    "* Fold batch normalization ops into weights (super cool)\n",
    "* Round weights\n",
    "* Quantize weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graph Transform Tool\n",
    "\n",
    "https://petewarden.com/2016/12/30/rewriting-tensorflow-graphs-with-the-gtt/\n",
    "\n",
    "https://github.com/tensorflow/tensorflow/tree/master/tensorflow/tools/graph_transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimize Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summarize Graph Utility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/root/tensorflow/bazel-bin/tensorflow/tools/graph_transforms/summarize_graph\n"
     ]
    }
   ],
   "source": [
    "%%bash \n",
    "\n",
    "which summarize_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 36\n",
      "-rw-r--r-- 1 root root 33509 May  8 01:55 metagraph.pb\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "## TODO: /root/models/linear/cpu/metagraph\n",
    "## ls -l /root/models/optimize_me/\n",
    "\n",
    "ls -l /root/models/linear/cpu/unoptimized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input checkpoint '' doesn't exist!\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "freeze_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'tensorflow.python.tools.freeze_graph' from '/opt/conda/lib/python3.5/site-packages/tensorflow/python/tools/freeze_graph.py'>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.python.tools import freeze_graph\n",
    "\n",
    "checkpoint_prefix = os.path.join(self.get_temp_dir(), \"saved_checkpoint\")\n",
    "checkpoint_state_name = \"checkpoint_state\"\n",
    "input_graph_name = \"input_graph.pb\"\n",
    "output_graph_name = \"output_graph.pb\"\n",
    "    \n",
    "input_graph_path = os.path.join(self.get_temp_dir(),\n",
    "                                input_graph_name)\n",
    "input_saver_def_path = \"\"\n",
    "input_binary = False\n",
    "output_node_names = \"output_node\"\n",
    "restore_op_name = \"save/restore_all\"\n",
    "filename_tensor_name = \"save/Const:0\"\n",
    "output_graph_path = os.path.join(self.get_temp_dir(), output_graph_name)\n",
    "clear_devices = False\n",
    "    \n",
    "freeze_graph.freeze_graph(input_graph_path,\n",
    "                          input_saver_def_path,\n",
    "                          input_binary, \n",
    "                          checkpoint_path,\n",
    "                          output_node_names,\n",
    "                          restore_op_name,\n",
    "                          filename_tensor_name,\n",
    "                          output_graph_path,\n",
    "                          clear_devices, \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[libprotobuf ERROR external/protobuf/src/google/protobuf/wire_format_lite.cc:621] String field 'tensorflow.NodeDef.op' contains invalid UTF-8 data when parsing a protocol buffer. Use the 'bytes' type if you intend to send raw bytes. \n",
      "[libprotobuf ERROR external/protobuf/src/google/protobuf/text_format.cc:299] Error parsing text-format tensorflow.GraphDef: 2:1: Interpreting non ascii codepoint 148.\n",
      "[libprotobuf ERROR external/protobuf/src/google/protobuf/text_format.cc:299] Error parsing text-format tensorflow.GraphDef: 2:1: Expected identifier, got: ï¿½\n",
      "2017-05-08 01:55:37.834259: E tensorflow/tools/graph_transforms/summarize_graph_main.cc:266] Loading graph '/root/models/linear/cpu/unoptimized/metagraph.pb' failed with Can't parse /root/models/linear/cpu/unoptimized/metagraph.pb as binary proto\n",
      "\t (both text and binary parsing failed for file /root/models/linear/cpu/unoptimized/metagraph.pb)\n",
      "2017-05-08 01:55:37.834328: E tensorflow/tools/graph_transforms/summarize_graph_main.cc:268] usage: summarize_graph\n",
      "Flags:\n",
      "\t--in_graph=\"\"                    \tstring\tinput graph file name\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "## TODO: /root/models/linear/cpu/unoptimized/metagraph.pb\n",
    "## summarize_graph --in_graph=/root/models/optimize_me/unoptimized_cpu.pb\n",
    "\n",
    "summarize_graph --in_graph=/root/models/linear/cpu/unoptimized/metagraph.pb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Strip Unused Nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "# TODO:  shuffle_batch??  x_observed_batch??\n",
    "transform_graph \\\n",
    "--in_graph=/root/models/optimize_me/unoptimized_cpu.pb \\\n",
    "--out_graph=/root/models/optimize_me/strip_unused_optimized_cpu.pb \\\n",
    "--inputs='x_observed,weights,bias' \\\n",
    "--outputs='add' \\\n",
    "--transforms='\n",
    "strip_unused_nodes'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "ls -l /root/models/optimize_me/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "summarize_graph --in_graph=/root/models/optimize_me/strip_unused_optimized_cpu.pb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "benchmark_model --graph=/root/models/optimize_me/strip_unused_optimized_cpu.pb --input_layer=weights,bias,x_observed --input_layer_type=float,float,float --input_layer_shape=:: --output_layer=add"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fold Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "transform_graph \\\n",
    "--in_graph=/root/models/optimize_me/unoptimized_cpu.pb \\\n",
    "--out_graph=/root/models/optimize_me/fold_constants_optimized_cpu.pb \\\n",
    "--inputs='x_observed,weights,bias' \\\n",
    "--outputs='add' \\\n",
    "--transforms='\n",
    "fold_constants(ignore_errors=true)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "ls -l /root/models/optimize_me/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "summarize_graph --in_graph=/root/models/optimize_me/fold_constants_optimized_cpu.pb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "benchmark_model --graph=/root/models/optimize_me/fold_constants_optimized_cpu.pb --input_layer=x_observed,bias,weights --input_layer_type=float,float,float --input_layer_shape=:: --output_layer=add"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fold Batch Normalizations\n",
    "Must run Fold Constants first!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "transform_graph \\\n",
    "--in_graph=/root/models/optimize_me/fold_constants_optimized_cpu.pb \\\n",
    "--out_graph=/root/models/optimize_me/fold_batch_norms_optimized_cpu.pb \\\n",
    "--inputs='x_observed,weights,bias' \\\n",
    "--outputs='add' \\\n",
    "--transforms='\n",
    "fold_batch_norms\n",
    "fold_old_batch_norms'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "ls -l /root/models/optimize_me/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "summarize_graph --in_graph=/root/models/optimize_me/fold_batch_norms_optimized_cpu.pb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "benchmark_model --graph=/root/models/optimize_me/fold_batch_norms_optimized_cpu.pb --input_layer=x_observed,bias,weights --input_layer_type=float,float,float --input_layer_shape=:: --output_layer=add"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quantize Weights\n",
    "Should run Fold Batch Norms first!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "transform_graph \\\n",
    "--in_graph=/root/models/optimize_me/fold_batch_norms_optimized_cpu.pb \\\n",
    "--out_graph=/root/models/optimize_me/quantized_optimized_cpu.pb \\\n",
    "--inputs='x_observed,weights,bias' \\\n",
    "--outputs='add' \\\n",
    "--transforms='quantize_weights'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "ls -l /root/models/optimize_me/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "summarize_graph --in_graph=/root/models/optimize_me/quantized_optimized_cpu.pb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "benchmark_model --graph=/root/models/optimize_me/quantized_optimized_cpu.pb --input_layer=x_observed,bias,weights --input_layer_type=float,float,float --input_layer_shape=:: --output_layer=add"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform All Common Optimizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "transform_graph \\\n",
    "--in_graph=/root/models/optimize_me/unoptimized_cpu.pb \\\n",
    "--out_graph=/root/models/optimize_me/fully_optimized_cpu.pb \\\n",
    "--inputs='x_observed,weights,bias' \\\n",
    "--outputs='add' \\\n",
    "--transforms='\n",
    "add_default_attributes\n",
    "remove_nodes(op=Identity, op=CheckNumerics)\n",
    "fold_constants(ignore_errors=true)\n",
    "fold_batch_norms\n",
    "fold_old_batch_norms\n",
    "quantize_weights\n",
    "quantize_nodes\n",
    "strip_unused_nodes\n",
    "obfuscate_names'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "ls -l /root/models/optimize_me/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "summarize_graph --in_graph=/root/models/optimize_me/fully_optimized_cpu.pb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "benchmark_model --graph=/root/models/optimize_me/fully_optimized_cpu.pb --input_layer=weights,x_observed,bias --input_layer_type=float,float,float --input_layer_shape=:: --output_layer=add"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sort by Execution Order (DAG Topological Order)\n",
    "* Minimizes inference overhead \n",
    "* Inputs for a node guaranteed to be available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "transform_graph \\\n",
    "--in_graph=/root/models/optimize_me/fully_optimized_cpu.pb \\\n",
    "--out_graph=/root/models/optimize_me/sort_by_execution_order_optimized_cpu.pb \\\n",
    "--inputs='x_observed,weights,bias' \\\n",
    "--outputs='add' \\\n",
    "--transforms='\n",
    "sort_by_execution_order'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "ls -l /root/models/optimize_me/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "summarize_graph --in_graph=/root/models/optimize_me/sort_by_execution_order_optimized_cpu.pb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "benchmark_model --graph=/root/models/optimize_me/sort_by_execution_order_optimized_cpu.pb --input_layer=weights,x_observed,bias --input_layer_type=float,float,float --input_layer_shape=:: --output_layer=add"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
